[241226(목) 14-1.메타DB 주요테이블 보기]
1. UI - Browse 
가. DAG Runs : select * from public.dag_run;
나. Audit Logs : select * from public.log; User별 모든 활동 기록
다. Task instance : select * from task_instance
라. Task Reschedule (+ sensor)

2. UI - Admin
가. Variables : select * from variable; # 복호화된 내용이 보이므로, 최소인원만 접근 가능하도록, 대량 정보 입력 필요시 DB에 직접 Insert 가능, 메타DB 매일 백업 필요
나. Configurations (+ Docker-compose.yaml, True 설정 후 확인 가능)
다. Connections : select * from connection ; # 복호화된 내용이 보이므로, 최소인원만 접근 가능하도록, 대량 정보 입력 필요시 DB에 직접 Insert 가능, 메타DB 매일 백업 필요
라. Plugins : hive 등, 소스코드 내 Plugins와 다름 + 커스텀 가능(+ web 화면 변경)
마. Providers : 없음
바. Pools : select * from slot_pool; 

3. Job 수행이력 삭제? dag_run (PK) > task_instance(FK) : dag_run에서 삭제시 task_instance에도 자동삭제

[241227(금) 14-2.Airflow Pool]
0. dags_bash_with_pool.py
1. Celery Excutor : Scheduled Slot > Queued Slot task 이동
2. 해당 DB용 Pool를 만들고 Slot 4개 할당 : 소스DB부하X, 즉 상황에 따라 Pool을 작게할 수 있다.
3. Dag이 여러개 있을 때 weight_rule에 따라서 task가 Scheduled Slot > Queued Slot task 이동
    1) upstream : 현재 Task의 상위 Task의 sum(Weight) > 수직, 특정 Dag이 시작되면 다른 Dag으로 넘어가지 않고 내부에 있는 Task들이 계속 수행될 가능성이 높음
    2) downstearm(default) : 현재 Task의 하위 Task의 sum(Weight) > 수평, Dag들의 상위 Task들 부터 수행될 가능성이 높음
4. pool_slots 3으로 설정 : 전체 6개 slot 중 무거운 Task가 수행될 때 3개만 Task가 수행될 수 있도록 하기위함

[241227(금) 14-3.Airflow 유저_그룹 만들기]
1. custom role 사용 잘 X > 있는 role 사용
2. 일반적으로 DAG 개발자마다 계정을 생성하고 User 혹은 Op Role 부여
3. Admin과 Op의 차이 : Security, Admin - Providers 차이